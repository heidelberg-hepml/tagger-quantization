iterations: 1000
batchsize: 128

optimizer: AdamW
lr: 1e-3
betas: [.9, .999]
eps: 1e-8
weight_decay: 0

lr_factor_framesnet: 1
weight_decay_framesnet: 0

scheduler: CosineAnnealingLR
scheduler_scale: 1
cosanneal_eta_min: 0
reduceplateau_factor: 0.1
reduceplateau_patience: 50
onecycle_max_lr: 10

es_patience: 100
es_load_best_model: true

log_every_n_steps: 200
validate_every_n_steps: 500
validate_every_n_epochs_min: null

log_grad_norm: true
clip_grad_norm_framesnet: null
clip_grad_norm: null
clip_grad_value: null
max_grad_norm: null
